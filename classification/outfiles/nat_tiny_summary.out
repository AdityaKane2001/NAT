NAT(
  (patch_embed): ConvTokenizer(
    (proj): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (levels): ModuleList(
    (0): NATBlock(
      (blocks): ModuleList(
        (0): NATLayer(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=2
            (qkv): Linear(in_features=64, out_features=192, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1-2): 2 x NATLayer(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=2
            (qkv): Linear(in_features=64, out_features=192, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=192, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=192, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): ConvDownsampler(
        (reduction): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): NATBlock(
      (blocks): ModuleList(
        (0-3): 4 x NATLayer(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): ConvDownsampler(
        (reduction): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): NATBlock(
      (blocks): ModuleList(
        (0-17): 18 x NATLayer(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): ConvDownsampler(
        (reduction): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): NATBlock(
      (blocks): ModuleList(
        (0-4): 5 x NATLayer(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=512, out_features=1000, bias=True)
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─ConvTokenizer: 1-1                     [-1, 56, 56, 64]          --
|    └─Sequential: 2-1                   [-1, 64, 56, 56]          --
|    |    └─Conv2d: 3-1                  [-1, 32, 112, 112]        896
|    |    └─Conv2d: 3-2                  [-1, 64, 56, 56]          18,496
|    └─LayerNorm: 2-2                    [-1, 56, 56, 64]          128
├─Dropout: 1-2                           [-1, 56, 56, 64]          --
├─ModuleList: 1                          []                        --
|    └─NATBlock: 2-3                     [-1, 28, 28, 128]         --
|    |    └─ConvDownsampler: 3-3         [-1, 28, 28, 128]         73,984
|    └─NATBlock: 2-4                     [-1, 14, 14, 256]         --
|    |    └─ConvDownsampler: 3-4         [-1, 14, 14, 256]         295,424
|    └─NATBlock: 2-5                     [-1, 7, 7, 512]           --
|    |    └─ConvDownsampler: 3-5         [-1, 7, 7, 512]           1,180,672
|    └─NATBlock: 2-6                     [-1, 7, 7, 512]           --
├─LayerNorm: 1-3                         [-1, 7, 7, 512]           1,024
├─AdaptiveAvgPool1d: 1-4                 [-1, 512, 1]              --
├─Linear: 1-5                            [-1, 1000]                513,000
==========================================================================================
Total params: 2,083,624
Trainable params: 2,083,624
Non-trainable params: 0
Total mult-adds (M): 297.09
==========================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 9.00
Params size (MB): 7.95
Estimated Total Size (MB): 17.53
==========================================================================================

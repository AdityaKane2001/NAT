NAT(
  (patch_embed): ConvTokenizer(
    (proj): Sequential(
      (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (levels): ModuleList(
    (0): NATBlock(
      (blocks): ModuleList(
        (0): NATLayer(
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=192, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=192, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1-2): 2 x NATLayer(
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=192, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=192, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): ConvDownsampler(
        (reduction): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): NATBlock(
      (blocks): ModuleList(
        (0-3): 4 x NATLayer(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): ConvDownsampler(
        (reduction): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): NATBlock(
      (blocks): ModuleList(
        (0-17): 18 x NATLayer(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=12
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): ConvDownsampler(
        (reduction): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): NATBlock(
      (blocks): ModuleList(
        (0-4): 5 x NATLayer(
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): NeighborhoodAttention2D(
            kernel_size=7, dilation=1, head_dim=32, num_heads=24
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=768, out_features=1000, bias=True)
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─ConvTokenizer: 1-1                     [-1, 56, 56, 96]          --
|    └─Sequential: 2-1                   [-1, 96, 56, 56]          --
|    |    └─Conv2d: 3-1                  [-1, 48, 112, 112]        1,344
|    |    └─Conv2d: 3-2                  [-1, 96, 56, 56]          41,568
|    └─LayerNorm: 2-2                    [-1, 56, 56, 96]          192
├─Dropout: 1-2                           [-1, 56, 56, 96]          --
├─ModuleList: 1                          []                        -- 
|    |  ToMeDownsampler                  [-1, 28, 28, 192]         166,272
|    └─NATBlock: 2-3                     [-1, 28, 28, 192]         --
|    └─NATBlock: 2-4                     [-1, 14, 14, 384]         --
|    |    └─ConvDownsampler: 3-4         [-1, 14, 14, 384]         664,320
|    └─NATBlock: 2-5                     [-1, 7, 7, 768]           --
|    |    └─ConvDownsampler: 3-5         [-1, 7, 7, 768]           2,655,744
|    └─NATBlock: 2-6                     [-1, 7, 7, 768]           --
├─LayerNorm: 1-3                         [-1, 7, 7, 768]           1,536
├─AdaptiveAvgPool1d: 1-4                 [-1, 768, 1]              --
├─Linear: 1-5                            [-1, 1000]                769,000
==========================================================================================
Total params: 4,299,976
Trainable params: 4,299,976
Non-trainable params: 0
Total mult-adds (M): 636.81
==========================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 13.50
Params size (MB): 16.40
Estimated Total Size (MB): 30.48
==========================================================================================
